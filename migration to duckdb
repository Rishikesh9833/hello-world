Perfect ‚Äî if you‚Äôre migrating from SQLite and want DuckDB to infer column types based on the actual data (rather than relying on SQLite‚Äôs often loose typing), the best approach is to use Pandas DataFrames as an intermediary. DuckDB will infer column types from the DataFrame‚Äôs dtypes, which are more precise.

---

üß† Smart Table Creation in DuckDB Based on Data

‚úÖ Recommended Approach: Use Pandas for Type Inference

Here‚Äôs how to ensure DuckDB creates columns with correct types:

import sqlite3
import duckdb
import pandas as pd

# Connect to SQLite and DuckDB
sqlite_conn = sqlite3.connect('old_database.sqlite')
duck_conn = duckdb.connect('new_database.duckdb')

# Get table names
cursor = sqlite_conn.cursor()
cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
tables = cursor.fetchall()

for table_name in tables:
    table = table_name[0]
    
    # Load data into Pandas
    df = pd.read_sql_query(f"SELECT * FROM {table}", sqlite_conn)
    
    # DuckDB infers types from DataFrame
    duck_conn.register('df_view', df)
    duck_conn.execute(f"CREATE TABLE {table} AS SELECT * FROM df_view")
    duck_conn.unregister('df_view')


---

üîç Why This Works Well

‚Ä¢ Pandas uses NumPy dtypes (`int64`, `float64`, `datetime64`, `object`, etc.)
‚Ä¢ DuckDB maps these to its internal types (`INTEGER`, `DOUBLE`, `TIMESTAMP`, `VARCHAR`, etc.)
‚Ä¢ This avoids issues like everything becoming `TEXT` in SQLite


---

üß™ Optional: Inspect Inferred Schema

You can verify the schema after creation:

duck_conn.execute(f"DESCRIBE {table}").fetchdf()


---

üß∞ Bonus: Handle Empty Tables Gracefully

If a table is empty, DuckDB can‚Äôt infer types. You can skip or handle it like this:

if not df.empty:
    duck_conn.register('df_view', df)
    duck_conn.execute(f"CREATE TABLE {table} AS SELECT * FROM df_view")
    duck_conn.unregister('df_view')
else:
    print(f"Skipping empty table: {table}")


---Here is the updated and enhanced migration script to move two SQLite databases into a single DuckDB database while handling:
	‚Ä¢	‚úÖ Accurate column type inference
	‚Ä¢	‚úÖ Auto-increment & primary key detection
	‚Ä¢	‚úÖ Duplicate table handling (merge or prefix)
	‚Ä¢	‚úÖ Schema mismatch prevention
	‚Ä¢	‚úÖ Null/NaN cleanup and deduplication
	‚Ä¢	‚úÖ Schema audit logging
	‚Ä¢	‚úÖ Progress reporting using tqdm
	‚Ä¢	‚úÖ Error logging

‚∏ª

‚úÖ Final Python Script (Ready to Run)

import sqlite3
import duckdb
import pandas as pd
import os
from tqdm import tqdm
import logging

# === Configuration ===
sqlite_paths = ['db1.sqlite', 'db2.sqlite']
duckdb_path = 'merged.duckdb'
merge_strategy = 'prefix'  # options: 'prefix', 'merge', 'skip'

# === Logging ===
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

# === Connect to DuckDB ===
duck_con = duckdb.connect(duckdb_path)
created_tables = set()
schema_log = []

# === Helper Functions ===
def infer_duckdb_types(df: pd.DataFrame):
    types = []
    for col in df.columns:
        series = df[col].dropna()
        if series.empty:
            types.append("TEXT")
        elif pd.api.types.is_integer_dtype(series):
            types.append("BIGINT")
        elif pd.api.types.is_float_dtype(series):
            types.append("DOUBLE")
        elif pd.api.types.is_bool_dtype(series):
            types.append("BOOLEAN")
        elif pd.api.types.is_datetime64_any_dtype(series):
            types.append("TIMESTAMP")
        else:
            types.append("TEXT")
    return types

def get_primary_key(cur, table):
    cur.execute(f"PRAGMA table_info({table})")
    for row in cur.fetchall():
        if row[-1] == 1:
            return row[1]  # column name
    return None

# === Main Loop ===
for db_index, sqlite_file in enumerate(sqlite_paths):
    if not os.path.exists(sqlite_file):
        logging.warning(f"File not found: {sqlite_file}")
        continue

    sqlite_con = sqlite3.connect(sqlite_file)
    sqlite_cur = sqlite_con.cursor()
    sqlite_cur.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = [row[0] for row in sqlite_cur.fetchall()]

    for table_name in tqdm(tables, desc=f"Migrating {os.path.basename(sqlite_file)}"):
        original_table = table_name
        df = pd.read_sql_query(f"SELECT * FROM {original_table}", sqlite_con)

        # Clean up data
        df.replace({"NaN": None, "null": None}, inplace=True)
        df = df.drop_duplicates()

        # Determine final DuckDB table name
        if merge_strategy == 'prefix':
            duckdb_table = f"db{db_index+1}_{table_name}"
        elif merge_strategy == 'merge':
            duckdb_table = table_name
        elif merge_strategy == 'skip' and table_name in created_tables:
            logging.info(f"Skipping table {table_name} (already migrated)")
            continue
        else:
            duckdb_table = table_name

        # Table creation
        if duckdb_table not in created_tables:
            duckdb_types = infer_duckdb_types(df)
            primary_key = get_primary_key(sqlite_cur, original_table)

            col_defs = []
            for col, dtype in zip(df.columns, duckdb_types):
                if col == primary_key:
                    col_defs.append(f"{col} BIGINT PRIMARY KEY AUTOINCREMENT")
                else:
                    col_defs.append(f"{col} {dtype}")

            create_sql = f"CREATE TABLE {duckdb_table} ({', '.join(col_defs)});"
            duck_con.execute(create_sql)
            created_tables.add(duckdb_table)

            schema_log.append({
                'table': duckdb_table,
                'columns': col_defs,
                'source_db': sqlite_file
            })

        # Insert
        duck_con.register("df_temp", df)
        try:
            duck_con.execute(f"INSERT INTO {duckdb_table} SELECT * FROM df_temp")
        except Exception as e:
            logging.error(f"Insert failed for table {duckdb_table}: {e}")
        duck_con.unregister("df_temp")

    sqlite_con.close()

# === Export Schema Audit ===
pd.DataFrame(schema_log).to_csv("duckdb_schema_audit.csv", index=False)
logging.info(f"‚úÖ Migration completed. Output: {duckdb_path}")


‚∏ª

üîÑ Merge Strategy Options

Change this line:

merge_strategy = 'prefix'

To:
	‚Ä¢	'merge': combine tables with same name across DBs
	‚Ä¢	'prefix': add db1_ / db2_ to avoid conflict
	‚Ä¢	'skip': skip duplicate table names

‚∏ª

üìÇ Output Files
	‚Ä¢	merged.duckdb: Your final combined database
	‚Ä¢	duckdb_schema_audit.csv: Schema summary of what was migrated

‚∏ª

Would you like:
	‚Ä¢	A CLI tool version?
	‚Ä¢	Web-based UI for selecting databases?
	‚Ä¢	Batch processing multiple .sqlite files from a folder?

Let me know and I‚Äôll tailor it accordingly.¬†Ôøº

Would you like to add automatic type validation or logging for each table‚Äôs schema during migration? I can help you build a reusable migration utility for this.